\begin{thm}
  Algorithm~\ref{alg:dgmm} (DGMM) will always generate a 2-optimal cover in $O(\Delta)$ communication rounds.
\label{thm:dgmm-term}
\end{thm}
\begin{note}[Mapping to Sequential Algorithm]
\label{not:gmm-dgmm}
DGMM is based on a sequential algorithm (GMM), which takes as an input a graph and produces a 2-optimal vertex cover of that graph. The sequential algorithm selects each edge of the graph in turn, in arbitrary order, and compares the endpoints of that edge. The edge is assigned a weight according to Equation~\ref{eqn:gmm}. If one endpoint is already in the cover, the resulting weight will be zero, otherwise, one endpoint will be added to the cover. When each edge has been assigned a weight, the algorithm terminates and outputs the cover.

For DGMM, the Graph is represented as a network of compute nodes, with the nodes representing vertexes and connections between the nodes representing edges. When the algorithm terminates, every node in the network that is in the cover should be in an ``on'' state, and every node that is not should either be an ``off'' state.
\end{note}
\begin{note}[Communication Model]
\label{not:com-model}
As mentioned in Section~\ref{ssb:com-model}, we assume a message passing model of distributed computing. In each communication round, it is assumed that every node can communicate with its neighbors. Communication is assumed to be synchronous and symetric: if node $a$ is a neighbor of node $b$, node $b$ is a neighbor of node $a$, and if node $a$ has counted $x$ communication steps, so has node $b$.

A ``communication round'' is actually three steps: an invitation sending step, an information response step, and an exchange step where neighbors share changes in status.\footnote{It should be noted that the K/Y algorithm also requires three communication events per round.} 
\end{note}
\begin{note}[Local Information]
\label{not:dgmm-local-info}
At the beginning of each communication round, each node has a list of it's neighbors, their current state, the edges associated with those neighbors, and the results of any previous computation performed on those edges.
\end{note}
\begin{proof}[Proof of Theorem~\ref{thm:dgmm-term}]
\label{prf:correct}
\begin{smy}
We show first that our algorithm conducts the same steps in the same order as a sequential algorithm that is known to produce a 2-optimal result, next that the algorithm will terminate in $O(\Delta)$ communication rounds.
\end{smy} 

\begin{lem}
\label{lem:dgmm-edge}
  DGMM examines each edge once in a manner equivalent to GMM.
\end{lem}
\begin{proof}[Proof of Lemma~\ref{lem:dgmm-edge}]

\end{proof}

\begin{lem}
  \label{lem:dgmm-delta}
  DGMM will terminate in $O(\Delta)$ communication rounds.
\end{lem}
\begin{proof}[Proof of Lemma~\ref{lem:dgmm-delta}]
In each communication round, roughly half of the nodes will choose to receive invitations. For each of these nodes, roughly half of their neighbors will be sending invitations, and the probability of receiving an invitation from one of these neighbors is $1:\Delta$. Taken together. As each node that receives one or more invitations will definitely respond to one invitation, in any given round, the probability of joining a node pair is $1:\Delta$. Of the two node pairs, one will weight a single edge, while the other will weight $\Delta$ edges, each of which will also be updated for $\Delta$ neighbors. This means that in a given round, roughly half of the nodes will make a decision for 1 of their edges, leading to a communications complexity of $O(2\Delta)$.
\end{proof}

Therefore, Theorem~\ref{thm:dgmm-term} is correct.
\end{proof}
