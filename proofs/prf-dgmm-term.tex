\begin{thm}
  Algorithm~\ref{alg:dgmm} (DGMM) will always generate a 2-optimal cover in $O(log\Delta)$ communication rounds.
\label{thm:dgmm-term}
\end{thm}
\begin{smy}
We show first that our algorithm conducts the same steps in the same order as a sequential algorithm that is known to produce a 2-optimal result, next that the algorithm will terminate in $O(log\Delta)$ communication rounds.
\end{smy} 

\begin{note}[Communication Model]
\label{not:com-model}
As mentioned in Section~\ref{ssb:com-model}, we assume a message passing model of distributed computing. In each communication round, it is assumed that every node can communicate with its neighbors. Communication is assumed to be synchronous and symetric: if node $a$ is a neighbor of node $b$, node $b$ is a neighbor of node $a$, and if node $a$ has counted $x$ communication steps, so has node $b$.

A ``communication round'' is actually three steps: an invitation sending step, an information response step, and an exchange step where neighbors share changes in status.\footnote{It should be noted that the K/Y algorithm also requires three communication events per round.} 
\end{note}
\begin{note}[Local Information]
\label{not:dgmm-local-info}
At the beginning of each communication round, each node has a list of its neighbors, their current state, the edges associated with those neighbors, and the results of any previous computation performed on those edges.
\end{note}
\begin{note}[Mapping to Sequential Algorithm]
\label{not:gmm-dgmm}
DGMM is based on a sequential algorithm (GMM), which takes as an input a graph and produces a 2-optimal vertex cover of that graph. The sequential algorithm selects each edge of the graph in turn, in arbitrary order, and compares the endpoints of that edge. The edge is assigned a weight according to Equation~\ref{eqn:gmm}. If one endpoint is already in the cover, the resulting weight will be zero, otherwise, one endpoint will be added to the cover. When each edge has been assigned a weight, the algorithm terminates and outputs the cover.

For DGMM, the Graph is represented as a network of compute nodes, with the nodes representing vertices and connections between the nodes representing edges. Nodes form pairs over these connections and assign weights to each connection following the same rules as the sequential algorithm. A node that joins the cover turns itself "on", while nodes turn off if they have no unweighted edges and have not joined the cover. When the algorithm terminates, every node in the network that is in the cover will be in an ``on'' state, and every node that is not will be in an ``off'' state.
\end{note}
\begin{proof}[Proof of Theorem~\ref{thm:dgmm-term}]
\label{prf:correct}

\begin{lem}
\label{lem:dgmm-edge}
  DGMM weights each edge once in a manner equivalent to GMM.
\end{lem}
\begin{proof}[Proof of Lemma~\ref{lem:dgmm-edge}]
  Lemma~\ref{lem:dgmm-edge} can be restated in terms of the following propositions.
  \begin{lprp}
    \label{prop:dgmm-edge-order}
    Given a matching, a simultaneous weighting of the edges in that matching is equivalent to an arbitrary sequential weighting of the same edges.
  \end{lprp}
  \begin{lprp}
    \label{prop:dgmm-edge-match}
    DGMM produces a matching in each communication round.
  \end{lprp}
  \begin{lprp}
    \label{prop:dgmm-edge-once}
    DGMM weights every edge exactly once.
  \end{lprp}
  If these propositions are true, Lemma~\ref{lem:dgmm-edge} is also true. 
  
  \begin{proof}[Proof of Proposition~\ref{prop:dgmm-edge-order}]
    Equation~\ref{eqn:gmm} for weighting an edge $e(u,v)$ is 
    \begin{equation*}
      weight(e(u,v)) = min
      \begin{dcases}
        weight(u) - \sum_{i \ne v} weight(e(u,i))\\
        weight(v) - \sum_{i \ne u} weight(e(v,i))
      \end{dcases}
    \end{equation*}
    By definition of a matching, no two edges in a matching share a vertex. Therefore, if an edge $e(u,v)$ is in the matching, no edge $e(u,i)$ is in the matching. 
    Take a matching \bMd\ in a Graph $G(V,E)$, composed of edges $\{e_0, e_1, ..., e_n\}$. If we use the sequential algorithm to weight the edges in \bMd\ one after the other, it is obvious that no edge outside of \bMd\ will change. Since only edges outside of \bMd\ are used to assign weights to edges inside \bMd\, it does not matter what order the weights are assigned in, or whether the weight assignment occurs to all edges in \bMd\ simultaneously.
    
    Therefore Proposition~\ref{prop:dgmm-edge-order} is true.
  \end{proof}
  \begin{proof}[Proof of Proposition~\ref{prop:dgmm-edge-match}]
    Assume not, that is, assume that there are two edges $e(u,v) \text{ and } e(u,i)$ that are both updated during the same communication round. For this to happen, some compute node $u$ must form a partnership with two nodes $i$ and $v$. 
    
At the beginning of every communication round, each node makes an equally weighted random decision to either issue an invitation or wait for invitations. We consider these options by cases.

    Case One: Assume that $v$ issues invitations. If $v$ issues invitations, $v$ will choose a single unweighted edge $(v,u)$ and broadcast an invitation with the id of $u$ to all of its neighbors (Line~\algref{alg:dgmm}{alglin:dgmm-issue-invite}). $v$ then transitions to the \cWd\ state. In this state, the node gathers all responses issued by its neighbors, and updates an edge if a response is sent specifically to .

    So if two edges are weighted, $v$ must receive two responses.

    Responses are issued by nodes in the \cRd\ state. Each node in this state chooses a single invitation from its received invitations and responds to it. Since $v$ gets two responses, therefore, $v$ must have invited two separate nodes in this round. But $v$ only issues one invitation, so this is a contradiction.

    Case Two: Assume that $v$ receives invitations. A node which recieves invitations updates the edge corresponding to the invitation it recieved. Since $v$ is weighting two edges, $v$ must respond to multiple invitations in this round. However, $v$ only sends a single response message (Line~\algref{alg:dgmm}{alglin:dgmm-choose-invite}., which is a contradiction as well.
    Therefore, Proposition~\ref{prop:dgmm-edge-match} is true.
  \end{proof}
  \begin{proof}[Proof of Proposition~\ref{prop:dgmm-edge-once}]
    Because a node will only attempt to weight an unweighted edge, we know that no edge will be weighted more than once. If the proposition is false, it must be the case that some edge is not weighted.
    For an edge to be unweighted, both endpoints of the edge would have to halt (enter the \cDd\ state) before the edge is weighted. Nodes halt under two circumstances:
    \begin{enumerate}
    \item The node has joined the cover.
    \item A nodes neighbors have all joined the cover.
    \end{enumerate}
    In the first case, the node will weight all of its unweighted edges to 0. In the second case, the node weights its own edges to 0 if the other endpoint is in the cover.
    Therefore, if the algorithm halts, all edges have been weighted once.
  \end{proof}
  Therefore, Lemma~\ref{lem:dgmm-edge}: our algorithm weights edges equivalently to the GMM algorithm. As we have indicated, prior work by Gonzalez has shown GMM to be 2-optimal, therefore DGMM is two optimal as well.
\end{proof}

\begin{lem}
  \label{lem:dgmm-delta}
  DGMM will weight all edges in approximately $log\Delta$ communication rounds.
\end{lem}

\begin{ldef}
A node is {\em committed} if it has joined the cover or if all of its neighbors have joined the cover.
\end{ldef}
\begin{ldef}
A node is {\em active} if it is not committed.
\end{ldef}
\begin{ldef}
$\Delta$ is the maximum degree of the Graph.
\end{ldef}
\begin{ldef}
\label{def:gamma}
For an node $u$, $\Gamma_u$ is the number of uncovered edges of $u$. $\Gamma$ is the average value of $\Gamma_u$ for all active nodes in the Graph. $\Gamma_u$ is equivalent to the number of active neighbors of $u$, and is bounded by $\Delta$. If $u$ is a committed node, $\Gamma_u$ is 0 by definition of committed.
\end{ldef}
\begin{ldef}
\label{def:omega}
The $\sigma$ node is a node that does not contribute to the discovery of the cover. When the algorithm starts, $\Gamma_\sigma$ is $\Delta$. The $\sigma$ node always fails to join the matching in every round.
\end{ldef}
\begin{note}
Only nodes that are still active at the end of a round participate in the next round. 
\end{note}
 
\begin{proof}[Proof of Lemma~\ref{lem:dgmm-delta}]
\begin{lprp}
\label{prop:dgmm-delta-average}
A random node $u$ in the graph will join the cover with some constant probability.
\end{lprp}
\begin{lprp}
\label{prop:dgmm-delta-sigma}
The $\sigma$ node is the worst case node.
\end{lprp}
\begin{lprp}
\label{prop:dgmm-delta-finish}
The $\sigma$ node will commit in $O(log \Delta)$ rounds.
\end{lprp}
\begin{proof}[Proof of Proposition~\ref{prop:dgmm-delta-average}]
In every round, a node $u$ must choose between two states, either the node will issue invitations or it will recieve invitations. This choice is made without bias. In any round, the probability that $u$ will choose to recieve invitations is $\sfrac{1}{2}$.

If $u$ chooses to be a reciever, $u$ must wait for invitations from its neighbors. Only the active neighbors which choose to be senders can send an invitation to $u$. We know from definition~\ref{def:gamma} that $u$ has $\Gamma_u$ active neighbors. Each of these neighbors choose to be senders with a probability of $\sfrac{1}{2}$, therefore $u$ has $\Gamma_u \times \sfrac{1}{2} = \sfrac{\Gamma_u}{2}$ neighbors which are senders. We can assume without loss of generality that $\Gamma_u \approx \Gamma$.

$\forall v \text{ incident to } u | v \text{ is a sender}$, $v$ has $\Gamma_v$ active neighbors. $v$ chooses one of these neighbors without bias and sends an invitation to that neighbor. Therefore, $\forall v \text{ incident to } u$, the probability that $v \text{ invites } u = \sfrac{1}{\Gamma_v}$. $\Gamma_v$ over all $v$ is an average, so we can assume without loss of generality that $\Gamma_v \approx \Gamma$.

If $u$ recieves at least one invitation, $u$ will respond to one invitation with a probability of $1$. The odds that $u$ will recieve an invitation are equal to the odds that $u$ is a reciever, times the number of neighbors of $u$ that are senders, times the odds that each sender will invite $u$.

\begin{equation*}
\frac{1}{2} \times \frac{\Gamma_u}{2} \times \frac{1}{\Gamma} = \frac{1}{4}
\end{equation*}

Therefore $u$ will participate in the matching with a probability of at least $\sfrac{1}{4}$. If $u$ chooses to be a sender, there is some probability that $u$ will be in the matching as well, but that circumstance cannot lower the probability that $u$ will be in the matching.

We know from the algorithm that if two nodes are endpoints of an edge in the matching, one of them must join the cover. The determination of which one depends on the initial weight and life history of the node, but for any arbitrary pair of nodes, we can assume that each has an equal chance of joining the cover. Therefore node $u$ will join the cover with probability of at least $\sfrac{1}{2} \times \sfrac{1}{4} = \sfrac{1}{8}$, which is constant.
\end{proof}
\begin{proof}[Proof of Proposition~\ref{prop:dgmm-delta-sigma}]
We know from Proposition~\ref{prop:dgmm-delta-average} that Algorithm~\ref{alg:dgmm} terminates. Since the algorithm can only terminate if the $\sigma$ node becomes committed, termination is dependent on every node incident to $\sigma$ joining the cover. Let us consider another node $u$ which is not the $\sigma$ node. $u$ only participates in the matching one time, and it's degree is also $\Delta$. $\sigma$ and $u$ have the same number of edges, and the neighbors of $\sigma$ and $u$ join the cover with equal probability in each round. However, we know that $u$ participates in the matching in at least one round. The probability that a node will participate in the matching is double the probability that a node will join the cover. Therefore $u$ will weight one of it's edges in $\sfrac{1}{2}$ the rounds that it takes $\sigma$ to weight one of it's edges. The remaining $\Delta - 1$ edges of $u$ and $\sigma$ will be weighted in approximately the same number of rounds, so we expect $u$ to terminate before $\sigma$. 

Therefore $\sigma$ is the worst case node. 
\end{proof}
\begin{proof}[Proof of Proposition~\ref{prop:dgmm-delta-finish}

\end{proof}
\end{proof}
Therefore, because DGMM weights all edges and assigns nodes to the cover in a manner equivalent to GMM in $O(log \Delta)$ communication rounds, Theorem~\ref{thm:dgmm-term} is correct.
\end{proof}
